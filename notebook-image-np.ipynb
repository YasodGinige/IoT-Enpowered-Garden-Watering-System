{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.utils import shuffle\nimport csv\nimport math \nfrom os import listdir\nfrom os.path import isfile, join\nfrom sklearn.model_selection import train_test_split\nmypath='../input/np-data/Python/ImageData/'\nonlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n\n#print(onlyfiles)\nX =[]\ny=[]\n#y=np.load('../input/nan-p-final/y_Back.npy',allow_pickle=True)\nMax=0\n\n\nfor j in range(len(onlyfiles)):\n    data = list(np.load(mypath+onlyfiles[j],allow_pickle=True))\n    X.append(data[:80])\n    y=y+[list(onlyfiles[j].split('_'))[0]]*80\n\nprint(y[220:320])\n\nonlyfiles=[]\nX_new=[]\nfor i in X:\n    for j in i:\n        p=128-len(j)\n        if p>0:\n            if p%2==0:\n                k1=p//2\n                k2=k1\n            else:\n                k1=int(np.floor(p/2))\n                k2=int(np.ceil(p/2))\n            \n            j=np.pad(j, [(k1, k2), (k1, k2)], mode='constant')\n            X_new.append([j]*3)\n            \n        else:\n            X_new.append([j]*3)\n        #i.remove(j)\n    #X.remove(i)\n        \nX=X_new     \nX_new=[]\nprint(\"Mark1\")\nX, y = shuffle(X, y)\nprint(\"Mark2\")\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, shuffle=False)\nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=False)\nprint(\"Mark3\")\n\nX_train=np.array(X_train)\ny_train=np.array(y_train)\nX_valid=np.array(X_valid)\ny_valid=np.array(y_valid)\nX_test=np.array(X_test)\ny_test=np.array(y_test)\n\nprint(\"X_train shape:\",X_train.shape)\nprint(\"X_valid shape:\",X_valid.shape)\nprint(\"X_test shape:\",X_test.shape)\nprint(\"y_train shape:\",y_train.shape)\nprint(\"y_valid shape:\",y_valid.shape)\nprint(\"y_test shape:\",y_test.shape)\n\npath='/Image_data/'\nnp.save('X_train.npy', X_train, allow_pickle=True)\nnp.save('X_valid.npy', X_valid, allow_pickle=True)\nnp.save('X_test.npy', X_test, allow_pickle=True)\nnp.save('y_train.npy', y_train, allow_pickle=True)\nnp.save('y_valid.npy', y_valid, allow_pickle=True)\nnp.save('y_test.npy', y_test, allow_pickle=True)\n\n\nfor i in range(1,20000,2000):\n    print(X_train[i][0].shape)\n\nprint(\"All saved\")\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-21T16:03:12.592600Z","iopub.execute_input":"2022-02-21T16:03:12.593353Z","iopub.status.idle":"2022-02-21T16:04:46.524237Z","shell.execute_reply.started":"2022-02-21T16:03:12.593212Z","shell.execute_reply":"2022-02-21T16:04:46.516802Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import gc\n\ndel X,X_new,onlyfiles,y,data\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T16:05:37.338075Z","iopub.execute_input":"2022-02-21T16:05:37.338408Z","iopub.status.idle":"2022-02-21T16:05:37.622838Z","shell.execute_reply.started":"2022-02-21T16:05:37.338375Z","shell.execute_reply":"2022-02-21T16:05:37.621809Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('../input/np-data/VGG16_128.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:16:06.459418Z","iopub.execute_input":"2022-02-21T15:16:06.459825Z","iopub.status.idle":"2022-02-21T15:16:14.805983Z","shell.execute_reply.started":"2022-02-21T15:16:06.459779Z","shell.execute_reply":"2022-02-21T15:16:14.805150Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(model.summary())\nmodel.add(Dense(256))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T15:25:39.172491Z","iopub.execute_input":"2022-02-21T15:25:39.174477Z","iopub.status.idle":"2022-02-21T15:25:39.267435Z","shell.execute_reply.started":"2022-02-21T15:25:39.174398Z","shell.execute_reply":"2022-02-21T15:25:39.266027Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D,BatchNormalization\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import ELU\nfrom tensorflow.keras.initializers import glorot_uniform\n\n\nfilter_num = ['None',32,64,128,256]\nkernel_size = ['None',8,8,8,8]\nconv_stride_size = ['None',1,1,1,1]\npool_stride_size = ['None',4,4,4,4]\npool_size = ['None',8,8,8,8]\n\ninput_shape=(3,128,128)\n\nmodel = Sequential()\nmodel.add(Conv2D(filters=filter_num[1], kernel_size=kernel_size[1], input_shape=input_shape,\n                         strides=conv_stride_size[1], padding='same',\n                         name='block1_conv1'))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(ELU(alpha=1.0, name='block1_adv_act1'))\nmodel.add(Conv2D(filters=filter_num[1], kernel_size=kernel_size[1],\n                         strides=conv_stride_size[1], padding='same',\n                         name='block1_conv2'))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(ELU(alpha=1.0, name='block1_adv_act2'))\nmodel.add(MaxPooling2D(pool_size=pool_size[1], strides=pool_stride_size[1],\n                               padding='same', name='block1_pool'))\nmodel.add(Dropout(0.1, name='block1_dropout'))\n\nmodel.add(Conv2D(filters=filter_num[2], kernel_size=kernel_size[2],\n                         strides=conv_stride_size[2], padding='same',\n                         name='block2_conv1'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu', name='block2_act1'))\n\nmodel.add(Conv2D(filters=filter_num[2], kernel_size=kernel_size[2],\n                         strides=conv_stride_size[2], padding='same',\n                         name='block2_conv2'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu', name='block2_act2'))\nmodel.add(MaxPooling2D(pool_size=pool_size[2], strides=pool_stride_size[3],\n                               padding='same', name='block2_pool'))\nmodel.add(Dropout(0.1, name='block2_dropout'))\n\nmodel.add(Conv2D(filters=filter_num[3], kernel_size=kernel_size[3],\n                         strides=conv_stride_size[3], padding='same',\n                         name='block3_conv1'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu', name='block3_act1'))\nmodel.add(Conv2D(filters=filter_num[3], kernel_size=kernel_size[3],\n                         strides=conv_stride_size[3], padding='same',\n                         name='block3_conv2'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu', name='block3_act2'))\nmodel.add(MaxPooling2D(pool_size=pool_size[3], strides=pool_stride_size[3],\n                               padding='same', name='block3_pool'))\nmodel.add(Dropout(0.1, name='block3_dropout'))\n\nmodel.add(Conv2D(filters=filter_num[4], kernel_size=kernel_size[4],\n                         strides=conv_stride_size[4], padding='same',\n                         name='block4_conv1'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu', name='block4_act1'))\nmodel.add(Conv2D(filters=filter_num[4], kernel_size=kernel_size[4],\n                         strides=conv_stride_size[4], padding='same',\n                         name='block4_conv2'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu', name='block4_act2'))\nmodel.add(MaxPooling2D(pool_size=pool_size[4], strides=pool_stride_size[4],\n                               padding='same', name='block4_pool'))\nmodel.add(Dropout(0.1, name='block4_dropout'))\n\nmodel.add(Flatten(name='flatten'))\nmodel.add(Dense(512, kernel_initializer=glorot_uniform(seed=0), name='fc1'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu', name='fc1_act'))\n\nmodel.add(Dropout(0.7, name='fc1_dropout'))\n\nmodel.add(Dense(512, kernel_initializer=glorot_uniform(seed=0), name='fc2'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu', name='fc2_act'))\n\nmodel.add(Dropout(0.5, name='fc2_dropout'))\n\nmodel.add(Dense(256, kernel_initializer=glorot_uniform(seed=0), name='fc3'))\nmodel.add(Activation('softmax', name=\"softmax\"))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-21T16:06:19.931161Z","iopub.execute_input":"2022-02-21T16:06:19.931509Z","iopub.status.idle":"2022-02-21T16:06:26.973999Z","shell.execute_reply.started":"2022-02-21T16:06:19.931467Z","shell.execute_reply":"2022-02-21T16:06:26.972842Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nfrom keras.utils import np_utils\n\nBATCH_SIZE=128\nNB_EPOCH=20\nVERBOSE=2\nNB_CLASSES=256\n\ny_train = np_utils.to_categorical(y_train, NB_CLASSES)\ny_valid = np_utils.to_categorical(y_valid, NB_CLASSES)\ny_test = np_utils.to_categorical(y_test, NB_CLASSES)\n\n\n\n\nfilepath = 'Image_NP.hdf5'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\nhistory = model.fit(X_train, y_train,\n\t\tbatch_size=BATCH_SIZE, epochs=NB_EPOCH,\n\t\tverbose=VERBOSE, validation_data=(X_valid, y_valid), callbacks=callbacks_list)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T16:06:32.676937Z","iopub.execute_input":"2022-02-21T16:06:32.677246Z","iopub.status.idle":"2022-02-21T16:47:01.520981Z","shell.execute_reply.started":"2022-02-21T16:06:32.677207Z","shell.execute_reply":"2022-02-21T16:47:01.518736Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"score_test = model.evaluate(X_test, y_test, verbose=VERBOSE)\nprint(\"Testing closed accuracy:\", score_test[1])","metadata":{"execution":{"iopub.status.busy":"2022-02-21T16:47:12.896515Z","iopub.execute_input":"2022-02-21T16:47:12.897528Z","iopub.status.idle":"2022-02-21T16:47:27.186794Z","shell.execute_reply.started":"2022-02-21T16:47:12.897474Z","shell.execute_reply":"2022-02-21T16:47:27.185733Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}